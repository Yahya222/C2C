{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import albumentations\n",
    "import torch.optim as optim\n",
    "from albumentations.pytorch import ToTensorV2, ToTensor\n",
    "\n",
    "from C2C.models.resnet import *\n",
    "from C2C import train\n",
    "from C2C.loss import KLDLoss\n",
    "from C2C.eval_model import *\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(12)\n",
    "torch.cuda.manual_seed(12)\n",
    "np.random.seed(12)\n",
    "random.seed(12)\n",
    "\n",
    "torch.backends.cudnn.deterministic=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data CSV\n",
    "\n",
    "- CSV file must contain following columns:\n",
    "    - path - location of each patch\n",
    "    - wsi - Unique identifier for WSI\n",
    "    - label - Label of WSI (Binary 0 or 1)\n",
    "    - is_valid - If WSI part of validation cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_PATH = '11-3-2021 celiac_normal_split.csv'\n",
    "df = pd.read_csv(CSV_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Hard Coding for Celiac vs Normal\n",
    "\n",
    "# def sample_path(li, bpath):\n",
    "    \n",
    "#     img_name = list(set([x.split('__')[0].split('_')[0] for x in li]))\n",
    "#     valid_name = random.sample(img_name, int(0.2*len(img_name)))\n",
    "#     train_name = list(set(img_name) - set(valid_name))\n",
    "        \n",
    "#     train_path = [os.path.join(bpath, x) for x in li if x.split('__')[0].split('_')[0] in train_name]\n",
    "#     valid_path = [os.path.join(bpath, x) for x in li if x.split('__')[0].split('_')[0] in valid_name]\n",
    "    \n",
    "#     return train_path, valid_path\n",
    "\n",
    "# def convert_list_to_nested_list(image_list):\n",
    "#     sample_df = pd.DataFrame({'patch_name': image_list})\n",
    "#     sample_df['img_name'] = sample_df['patch_name'].apply(lambda x: x.split('/')[-1].split('__')[0])\n",
    "#     return list(sample_df.groupby('img_name')['patch_name'].apply(list))\n",
    "\n",
    "\n",
    "# def extract_celiac_normal_df():\n",
    "    \n",
    "#     base_path = '/project/GutIntelligenceLab/ys5hd/MSDS/images_512x512_non_resized/threshold_0.5/'    \n",
    "\n",
    "#     celiac_path = os.path.join(base_path, 'train/Celiac')\n",
    "#     normal_path = os.path.join(base_path, 'train/Normal')    \n",
    "\n",
    "#     # Extract Celiac\n",
    "#     celiac_train, celiac_valid = sample_path(os.listdir(celiac_path), celiac_path)\n",
    "#     # Extract Normal\n",
    "#     normal_train, normal_valid = sample_path(os.listdir(normal_path), normal_path)\n",
    "\n",
    "#     # Train Patches\n",
    "#     train_patches = celiac_train + normal_train\n",
    "#     # Valid Patches\n",
    "#     valid_patches = celiac_valid + normal_valid   \n",
    "\n",
    "#     # Train Image List\n",
    "#     train_images = convert_list_to_nested_list(train_patches)\n",
    "#     # Valid Image List\n",
    "#     valid_images = convert_list_to_nested_list(valid_patches)\n",
    "\n",
    "#     df = pd.DataFrame({'path': train_patches+valid_patches})\n",
    "#     df['wsi'] = df['path'].apply(lambda x: x.split('/')[-1].split('__')[0])\n",
    "\n",
    "#     train_img_name = [x[0].split('/')[-1].split('__')[0] for x in train_images]\n",
    "\n",
    "#     df['is_valid'] = 1\n",
    "#     df.loc[df['wsi'].isin(train_img_name), 'is_valid'] = 0\n",
    "#     df['label'] = df['wsi'].str.startswith('C')\n",
    "    \n",
    "#     return df\n",
    "\n",
    "# df = extract_celiac_normal_df()\n",
    "\n",
    "# def sample_for_testing(df):\n",
    "#     sample_for_check = df[df['wsi'].str.startswith('C')]['wsi'][:5].tolist() + df[(df['wsi'].str.startswith('C')) & (df['is_valid']==1)]['wsi'][:5].tolist()\\\n",
    "#     + df[~df['wsi'].str.startswith('C')]['wsi'][:5].tolist() + df[(~df['wsi'].str.startswith('C')) & (df['is_valid']==1)]['wsi'][:5].tolist()\n",
    "#     df = df.loc[df['wsi'].isin(sample_for_check)].reset_index(drop=True)\n",
    "    \n",
    "#     return df \n",
    "\n",
    "# df = sample_for_testing(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>wsi</th>\n",
       "      <th>is_valid</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/project/GutIntelligenceLab/ys5hd/MSDS/images_...</td>\n",
       "      <td>C06-28_05</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/project/GutIntelligenceLab/ys5hd/MSDS/images_...</td>\n",
       "      <td>C10-50_01</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/project/GutIntelligenceLab/ys5hd/MSDS/images_...</td>\n",
       "      <td>C10-48_01</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/project/GutIntelligenceLab/ys5hd/MSDS/images_...</td>\n",
       "      <td>C15-74_04</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/project/GutIntelligenceLab/ys5hd/MSDS/images_...</td>\n",
       "      <td>C07-40_01</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path        wsi  is_valid  \\\n",
       "0  /project/GutIntelligenceLab/ys5hd/MSDS/images_...  C06-28_05         0   \n",
       "1  /project/GutIntelligenceLab/ys5hd/MSDS/images_...  C10-50_01         0   \n",
       "2  /project/GutIntelligenceLab/ys5hd/MSDS/images_...  C10-48_01         0   \n",
       "3  /project/GutIntelligenceLab/ys5hd/MSDS/images_...  C15-74_04         0   \n",
       "4  /project/GutIntelligenceLab/ys5hd/MSDS/images_...  C07-40_01         0   \n",
       "\n",
       "   label  \n",
       "0   True  \n",
       "1   True  \n",
       "2   True  \n",
       "3   True  \n",
       "4   True  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Model\n",
    "model_ft = WSIClassifier(2, bn_track_running_stats=True)\n",
    "model_ft = model_ft.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss, Optimizer, and Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Transforms\n",
    "data_transforms = albumentations.Compose([\n",
    "    ToTensor()\n",
    "    ])    \n",
    "\n",
    "# Cross Entropy Loss \n",
    "criterion_ce = nn.CrossEntropyLoss()\n",
    "criterion_kld = KLDLoss()\n",
    "criterion_dic = {'CE': criterion_ce, 'KLD': criterion_kld}\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer = optim.Adam(model_ft.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:00<00:00, 300013.33it/s]\n",
      "  0%|          | 0/275 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 275/275 [11:23<00:00,  2.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No KLD for cluster with 1 patch\n",
      "No KLD for cluster with 1 patch\n",
      "No KLD for cluster with 1 patch\n",
      "No KLD for cluster with 1 patch\n",
      "No KLD for cluster with 1 patch\n",
      "No KLD for cluster with 1 patch\n",
      "No KLD for cluster with 1 patch\n",
      "No KLD for cluster with 1 patch\n",
      "No KLD for cluster with 1 patch\n",
      "No KLD for cluster with 1 patch\n",
      "No KLD for cluster with 1 patch\n",
      "No KLD for cluster with 1 patch\n",
      "No KLD for cluster with 1 patch\n",
      "No KLD for cluster with 1 patch\n",
      "No KLD for cluster with 1 patch\n",
      "No KLD for cluster with 1 patch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/51 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss Patch: 0.6918 Loss WSI: 0.6016 Loss KLD: 0.0761 Acc: 0.6727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [01:54<00:00,  2.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.8431372549019608\n",
      "Predicted  Disease  Normal\n",
      "Actual                    \n",
      "Disease         23       7\n",
      "Normal           1      20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:00<00:00, 87703.77it/s]\n",
      "  0%|          | 0/275 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 275/275 [11:28<00:00,  2.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMI: 0.3870952762972492\n",
      "No KLD for cluster with 1 patch\n",
      "No KLD for cluster with 1 patch\n",
      "No KLD for cluster with 1 patch\n",
      "No KLD for cluster with 1 patch\n",
      "No KLD for cluster with 1 patch\n",
      "No KLD for cluster with 1 patch\n",
      "No KLD for cluster with 1 patch\n",
      "No KLD for cluster with 1 patch\n",
      "No KLD for cluster with 1 patch\n",
      "No KLD for cluster with 1 patch\n",
      "No KLD for cluster with 1 patch\n",
      "No KLD for cluster with 1 patch\n",
      "No KLD for cluster with 1 patch\n",
      "No KLD for cluster with 1 patch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/51 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss Patch: 0.6343 Loss WSI: 0.3922 Loss KLD: 0.4009 Acc: 0.8255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [02:01<00:00,  2.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.9019607843137255\n",
      "Predicted  Disease  Normal\n",
      "Actual                    \n",
      "Disease         27       3\n",
      "Normal           2      19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:00<00:00, 32702.87it/s]\n",
      "  0%|          | 0/275 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 275/275 [11:26<00:00,  2.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMI: 0.5414147104626258\n",
      "No KLD for cluster with 1 patch\n",
      "No KLD for cluster with 1 patch\n",
      "No KLD for cluster with 1 patch\n",
      "No KLD for cluster with 1 patch\n",
      "No KLD for cluster with 1 patch\n",
      "No KLD for cluster with 1 patch\n",
      "No KLD for cluster with 1 patch\n",
      "No KLD for cluster with 1 patch\n",
      "No KLD for cluster with 1 patch\n",
      "No KLD for cluster with 1 patch\n",
      "No KLD for cluster with 1 patch\n",
      "No KLD for cluster with 1 patch\n",
      "No KLD for cluster with 1 patch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/51 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss Patch: 0.5878 Loss WSI: 0.3051 Loss KLD: 0.4260 Acc: 0.8545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 29/51 [01:16<01:18,  3.58s/it]Exception ignored in: <generator object tqdm.__iter__ at 0x7fbf1437b150>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ys5hd/.local/lib/python3.7/site-packages/tqdm/std.py\", line 1131, in __iter__\n",
      "    yield obj\n",
      "KeyboardInterrupt: \n",
      " 57%|█████▋    | 29/51 [01:18<00:59,  2.72s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-9dc3c7dd2b4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m model_ft = train.train_model(model_ft, criterion_dic, optimizer, df, data_transforms=data_transforms,\\\n\u001b[0;32m----> 2\u001b[0;31m                              alpha=1, beta=0.01, gamma=0.01, num_epochs=20, fpath='trained/checkpoint.pt')\n\u001b[0m",
      "\u001b[0;32m/sfs/lustre/bahamut/scratch/ys5hd/MILClassifier-MIDL/C2C/train.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion_dic, optimizer, df, data_transforms, alpha, beta, gamma, num_cluster, num_img_per_cluster, num_epochs, fpath)\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# Set model to evaluate mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m                 \u001b[0mepoch_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_images_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_transforms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_transforms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mepoch_acc\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mbest_acc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/sfs/lustre/bahamut/scratch/ys5hd/MILClassifier-MIDL/C2C/eval_model.py\u001b[0m in \u001b[0;36meval_model\u001b[0;34m(test_images, test_images_label, model, data_transforms)\u001b[0m\n\u001b[1;32m     21\u001b[0m             tdl = torch.utils.data.DataLoader(td, batch_size=128,\n\u001b[1;32m     22\u001b[0m                                              shuffle=False, num_workers=0)\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mt_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_attn_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtdl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0mpred_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mpred_fname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/sfs/lustre/bahamut/scratch/ys5hd/MILClassifier-MIDL/C2C/eval_model.py\u001b[0m in \u001b[0;36mcompute_attn_df\u001b[0;34m(tdl, model, track_running_stats)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mfname_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mattn_rep_instance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp_rep_instance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menc_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mattn_rep_instance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn_rep_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/sfs/lustre/bahamut/scratch/ys5hd/MILClassifier-MIDL/C2C/dataloader.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mim_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_ft = train.train_model(model_ft, criterion_dic, optimizer, df, data_transforms=data_transforms,\\\n",
    "                             alpha=1, beta=0.01, gamma=0.01, num_epochs=20, fpath='trained/checkpoint.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from C2C.utils import *\n",
    "\n",
    "ckp_path = \"/scratch/ys5hd/Classification/AutoEncoder/checkpoint/checkpoint_celiac_1wsi_0.01kld_0.01p_512-256-64_val15_final_8_8.pt\"\n",
    "model_ft, optimizer = load_ckp(ckp_path, model_ft, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_PATH = '11-3-2021 celiac_normal_test_split.csv'\n",
    "df_test = pd.read_csv(TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [03:43<00:00,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.8655970794504756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pred_df = eval_test(model_ft, df_test, data_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 1.5.1 Py3.7",
   "language": "python",
   "name": "pytorch-1.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
